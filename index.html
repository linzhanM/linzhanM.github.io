<!DOCTYPE html>
<html lang="en">

<head>
    <base target="_blank" />
    <link rel="icon" type="image/x-icon" href="images/zju.png" />
    <link rel="preconnect" href="https://fonts.gstatic.com" />
    <link rel="stylesheet" type="text/css" data-href="https://fonts.googleapis.com/css?family=Lato" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <meta name="viewport" content="width=device-width" />
    <meta charSet="utf-8" />
    <title>Linzhan Mou&#x27;s Homepage</title>
    <meta name="description" content="I am a third-year undergraduate student in the Chu Kochen Honors College, Department of Automation at Zhejiang University. Currently, I’m working as a research intern at the State Key Laboratory of CAD&#x26;CG, supervised by Prof. Xiaowei Zhou. My research interest lies in the field of 3D Computer Vision, particularly including 3D reconstruction and generation, as well as their applications in mixed reality and robotics. And my overall GPA is 3.99/4.0, ranking top 2%. I am looking for potential summer internships!

" />
    <meta name="next-head-count" content="4" />
    <link rel="preload" href="_next/static/css/fd4c9bf86266e80fae27.css" as="style" />
    <link rel="stylesheet" href="_next/static/css/fd4c9bf86266e80fae27.css" data-n-g="" />
    <link rel="preload" href="_next/static/css/06137d006fb8a4f27819.css" as="style" />
    <link rel="stylesheet" href="_next/static/css/06137d006fb8a4f27819.css" data-n-p="" /><noscript
        data-n-css=""></noscript>
    <script defer="" nomodule="" src="_next/static/chunks/polyfills-a54b4f32bdc1ef890ddd.js"></script>
    <script src="_next/static/chunks/webpack-715970c8028b8d8e1f64.js" defer=""></script>
    <script src="_next/static/chunks/framework-64eb7138163e04c228e4.js" defer=""></script>
    <script src="_next/static/chunks/main-a1e4c023c7319bf8fa1e.js" defer=""></script>
    <script src="_next/static/chunks/pages/_app-3fa27215a3c41987e6d2.js" defer=""></script>
    <script src="_next/static/chunks/688-b942890a87f9a08b0e31.js" defer=""></script>
    <script src="_next/static/chunks/pages/index-1c2ddd10c81c1e933166.js" defer=""></script>
    <script src="_next/static/vDNOSUkFZmCqphQb-871s/_buildManifest.js" defer=""></script>
    <script src="_next/static/vDNOSUkFZmCqphQb-871s/_ssgManifest.js" defer=""></script>
    <style data-href="https://fonts.googleapis.com/css?family=Lato">
        @font-face{font-family:'Lato';font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/lato/v23/S6uyw4BMUTPHjx4wWA.woff) format('woff')}@font-face{font-family:'Lato';font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/lato/v23/S6uyw4BMUTPHjxAwXiWtFCfQ7A.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Lato';font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/lato/v23/S6uyw4BMUTPHjx4wXiWtFCc.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}
    </style>
</head>

<body>
    <div id="__next">
        <div class="styles_container__1_WuM">
            <section>
                <div class="personal_profile__BdQI4"><img class="personal_portrait__BAkO0" src="images/1.JPG"
                        alt="pottrait" />
                    <div class="personal_profileInfo__1Y4pW">
                        <h1 class="personal_name__1_mHK">Linzhan Mou</h1>
                        <h3 class="personal_chineseName__18aOD">牟林湛</h3>
                        <h3 class="personal_worksFor__2L0De">Zhejiang University</h3>
                        <div class="personal_links__p_eYL"><span>
                            <a href="mailto:moulz@zju.edu.cn">Email</a></span><span>
                            <a href="https://github.com/Friedrich-M">GitHub</a></span><span>
                            <a href="https://twitter.com/LinzhanMou">Twitter</a></span><span>
                            <!-- <a href="https://scholar.google.com/citations?user=cIXq7Z4AAAAJ&hl=en">Google Scholar</a></span><span> -->
                            <a href="./cv/resume.pdf">CV</a></span>
                        </div>
                    </div>
                </div>
            </section>
            <section>
                <h2>About Me</h2>
                <div>
                    <p>
                        I am a third-year undergraduate student, majoring in Automation from <b><a href="http://ckc.zju.edu.cn/ckcen/"> Chu Kochen Honors College</a></b> at <b><a
                            href="https://www.zju.edu.cn/english/">Zhejiang University</a></b>. 
                        Currently, I'm working as a research intern at the <b><a href="https://github.com/zju3dv">ZJU3DV Group</a></b> of <b><a href="http://www.cad.zju.edu.cn/english.html">State Key Laboratory of CAD&#x26;CG</a></b>, supervised by  <b><a href="https://xzhou.me/">Prof. Xiaowei Zhou</a></b>. And I'm also fortunately advised by  <b><a href="https://yxw.cs.illinois.edu/">Prof. Yuxiong Wang </a></b> as a undergraduate research assistant at <b><a href="https://cs.illinois.edu/">UIUC</a></b>.
                        My research interest lies in the field of <b>3D Computer Vision and AIGC</b>, particularly including <b>diffusion-based generation and 3D reconstruction</b>, as well as their applications in <b>mixed reality and robotics</b>. 
                        <!-- My ultimate goal is to enable embodied agents to better perceive and interact with the physical world. -->
                    </p>

                </div>
            </section>


            <section>
                <h2>Research Experiences</h2>
                <ul>
                    
                    <li> <b><a href="http://www.cad.zju.edu.cn/english.html">State Key Lab of CAD&#x26;CG, Department of Computer Science.</a></b>
                        </span> </span> &nbsp  Zhejiang University, CN<br> 
                        Supervised by <b><a href="https://scholar.google.com/citations?user=E1vVpg4AAAAJ&hl=en">
                            Prof. Xiaowei Zhou </a></b> &nbsp (Jun.2022---Present)
                    </li>
                    <ul>
                        <li>
                            Semantics-guided view synthesis of natural scenes from single-view images.(CVPR2023)
                        </li>
                        <li>
                            Neural relightable & animatable human avatar from sparse-view video.(SIGGRAPH2023)
                        </li>
                        <li>
                            Compact neural volumetric video representations with dynamic codebooks.(NIPS2023*)
                        </li>
                    </ul>

                    <li>  <b><a href="https://cs.illinois.edu/">Yu-Lab, Department of Computer Science.</a></b>
                    </span> </span> &nbsp University of Illinois at Urbana-Champaign, USA <br>
                    Supervised by <b><a href="https://scholar.google.com/citations?user=T_Q-xDkAAAAJ&hl=en">
                        Prof. Yuxiong Wang </a></b> &nbsp  (Feb.2023---Present)
                    </li>
                    <ul>
                        <li>
                            Improve instruct nerf2nerf by distilling features with VSD and apply global instruction.
                        </li>
                    </ul>

                   
                    <li> <b><a href="https://april.zju.edu.cn/">Advanced Perception on Robotics and Intelligent Learning Lab.</a></b>
                        </span> </span> &nbsp Zhejiang University, CN <br>
                        Supervised by <b><a href="https://scholar.google.com/citations?hl=en&user=qYcgBbEAAAAJ"> Prof. Yong Liu </a></b> &nbsp (Dec.2021---May.2023)
                    </li>
                    <ul>
                        <li>
                            AttFace: High-resolution face swapping with self-attention network.(IEEE Trans. 1<sup>st*</sup>) 
                        </li>

                        <li>
                            Multimodal-driven talking face generation <i>via</i> a diffusion-based generator.
                        </li>
                    </ul>

                   

                </ul>
                <div class="styles_showMore__JvZFs"><button>show more</button></div>
            </section>

            <section>
                <h2>Publications and Preprints</h2>

                <div class="publication-list_smallText__pUJXB">*equal contribution; ♯corresponding author.</div>

                <div class="publication_publication__1Icb_">
                    <div class="publication_image__1EUuC"><img src="images/NIPS.png"
                        alt="Reconstructing Hand-Held Objects from Monocular Video thumbnail loading..." />
                </div>
                    <div class="publication_info__kLRGP">
                        <div class="publication_title__3m6SE"> <b>CompactVV: Compact Neural Volumetric Video Representations with Dynamic Codebooks</b>
                        </div>
                        <div class="publication_authors__qkFXc"><span>  Anonymous authors</span> </div>
                        <div class="publication_venue__1Dv6R"><span><b><i>NeurIPS 2023</i></b></span><span></span> (review scores: 7 7 6 5 5) </div>
                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a>Paper</a></span>
                            <span class="publication_link__fXY43"><a>Project</a></span>
                            <span class="publication_link__fXY43"><a>Code</a></span></div>
                    </div>
                </div>

                <div class="publication_publication__1Icb_">
                    <div class="publication_image__1EUuC"><video muted="muted" autoplay="autoplay" loop>
                        <source src="images/sigasia.mp4">
                      </video>
                    </div>
                    <div class="publication_info__kLRGP">
                        <div class="publication_title__3m6SE"> <b>Neural Relightable & Animatable Human Avatar From Sparse-View Video</b>
                        </div>
                        <div class="publication_authors__qkFXc"><span> Anonymous authors</span> </div>
                        <div class="publication_venue__1Dv6R"><span><b><i>SIGGRAPH Asia 2023</i></b></span><span></span>(under review) </div>
                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a>Paper</a></span>
                            <span class="publication_link__fXY43"><a href="https://zhenx.me/relightable_avatar/">Project</a></span>
                            <span class="publication_link__fXY43"><a>Code</a></span></div>
                    </div>
                </div>

                <div>
                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><video muted="muted" autoplay="autoplay" loop>
                            <source src="images/teaser.mp4">
                          </video>
                        </div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE"><b>Painting 3D Nature in 2D: View Synthesis of Natural Scenes from a Single Semantic Mask</b></div>
                            <div class="publication_authors__qkFXc"><span>
                                    <span><a href="https://zhanghe3z.github.io/">Shangzhan Zhang</a></span>, 
                                    <span><a href="http://pengsida.net/">Sida Peng</a></span>, 
                                    <span><a href="https://tianrun-chen.github.io/">Tianrun Chen</a></span>, 
                                    <span><b><u>Linzhan Mou</u></b></span>, 
                                    <span><a href="https://haotongl.github.io/">Haotong Lin</a></span>, 
                                    <span><a href="https://scholar.google.com/citations?user=Jtmq_m0AAAAJ">Kaicheng Yu</a></span>, 
                                    <span><a href="https://yiyiliao.github.io/">Yiyi Liao</a></span>, 
                                    <span><a href="https://xzhou.me/">Xiaowei Zhou</a><sup>♯</sup></span></div>
                            <div class="publication_venue__1Dv6R"><span><b><i>CVPR 2023</i></b> (arxiv:2302.07224)</span>  </div>
                            <div class="publication_links__aEpO_">
                                        <span class="publication_link__fXY43"><a href="https://arxiv.org/pdf/2302.07224.pdf">Paper</a></span>
                                        <span class="publication_link__fXY43"><a href="https://zju3dv.github.io/paintingnature//">Project</a></span>
                                        <!-- <span class="publication_link__fXY43"><a href="https://zju3dv.github.io/paintingnature//">Code</a></span> -->
                                        <span class="publication_link__fXY43"><a href="./media/cvpr.pptx">Slide</a></span>

                            </div>
                        </div>
                    </div>
                    

                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><img src="images/attface.png">
                        </div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE"> <b>AttFace: High-Resolution Face Swapping with Attention Network</b>
                            </div>
                            <div class="publication_authors__qkFXc">
                                <span><b><u>Linzhan Mou*</u></b></span> 
                                <span><a href="https://zst1406217.github.io/">Shaoting Zhu*</a></span>
                                <span>Junyi Shen</span> 
                                <span><a href="https://april.zju.edu.cn/team/chao-xu/">Chao Xu</a></span> 
                                <span><a href="https://april.zju.edu.cn/team/dr-yong-liu/">Yong Liu</a><sup>♯</sup></span>  
                            </div>
                            <div class="publication_venue__1Dv6R"><span><b><i>IEEE Transactions on Computational Imaging (TCI)</i></b></div>
                            <div class="publication_venue__1Dv6R"><span>My first research project! (* equal contribution)</div>
                            <div class="publication_links__aEpO_">
                                <span class="publication_link__fXY43"><a href="./media/AttFace.pdf">Paper</a></span>
                                <span class="publication_link__fXY43"><a>Project</a></span>
                                <span class="publication_link__fXY43"><a>Code</a></span></div>
                        </div>
                    </div>


                </div>
            </section>

            <section>
                <h2>Selected Awards and Honors</h2>
                <ul>
                    <li>
                        <div style="display:inline"><i>2020 - 2021</i><!-- -->, </div><span
                            class="styles_collaborator__VflHz"><b>National Scholarship, Ministry of Education of P.R. China (Top 1%)</b> </span>
                    </li>
                    <li>
                        <div style="display:inline"><i>2020 - 2021</i><!-- -->, </div><span
                            class="styles_collaborator__VflHz"><b>1<sup>st</sup> Class Scholarship of Zhejiang University (Top 3%) </b> </span>
                    </li>
                    <li>
                        <div style="display:inline"><i>2021 - 2022</i><!-- -->, </div><span
                            class="styles_collaborator__VflHz"><b>Government Scholarship of Zhejiang Province (Top 3%) </b></span>
                    </li>
                    <li>
                        <div style="display:inline"><i>2021 - 2022</i><!-- -->, </div><span class="styles_collaborator__VflHz"><b>The Supcon
                            Scholarship, Supcon Technology Group (Top 5%)</b></span>
                    </li>
                    <li>
                        <div style="display:inline"><i>2022</i><!-- -->, </div><span
                            class="styles_collaborator__VflHz"> <b> China Undergraduate Mathematical Contest in Modeling — National First Prize
                            <!-- [<a href="http://www.mcm.edu.cn/upload_cn/node/629/uJzoCRK40ebedd130f42ed41e5f144ac29bae490.pdf"> pdf </a></b> </span>] -->
                    </li>
                    <li>
                        <div style="display:inline"><i>2022</i><!-- -->, </div><span
                            class="styles_collaborator__VflHz"> <b> International Genetically Engineered Machine Competition - International Gold Prize
                    </li>
                </ul>

           
        </div>
    </div>
</body>

</html>

