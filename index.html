<!DOCTYPE html>
<html lang="en">

<head>
    <base target="_blank" />
    <link rel="icon" type="image/x-icon" href="images/zju.png" />
    <link rel="preconnect" href="https://fonts.gstatic.com" />
    <link rel="stylesheet" type="text/css" data-href="https://fonts.googleapis.com/css?family=Lato" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <meta name="viewport" content="width=device-width" />
    <meta charSet="utf-8" />
    <title>Linzhan Mou&#x27;s Homepage</title>
    <meta name="description" content="I am a third-year undergraduate student in the Chu Kochen Honors College, Department of Automation at Zhejiang University. Currently, I'm working as a research intern at the State Key Laboratory of CAD&#x26;CG, supervised by Prof. Xiaowei Zhou. My research interest lies in the field of 3D Computer Vision, particularly including 3D reconstruction and generation, as well as their applications in mixed reality and robotics. And my overall GPA is 3.99/4.0, ranking top 2%. I am looking for potential summer internships!

" />
    <meta name="next-head-count" content="4" />
    <link rel="preload" href="_next/static/css/fd4c9bf86266e80fae27.css" as="style" />
    <link rel="stylesheet" href="_next/static/css/fd4c9bf86266e80fae27.css" data-n-g="" />
    <link rel="preload" href="_next/static/css/06137d006fb8a4f27819.css" as="style" />
    <link rel="stylesheet" href="_next/static/css/06137d006fb8a4f27819.css" data-n-p="" /><noscript
        data-n-css=""></noscript>
    <script defer="" nomodule="" src="_next/static/chunks/polyfills-a54b4f32bdc1ef890ddd.js"></script>
    <script src="_next/static/chunks/webpack-715970c8028b8d8e1f64.js" defer=""></script>
    <script src="_next/static/chunks/framework-64eb7138163e04c228e4.js" defer=""></script>
    <script src="_next/static/chunks/main-a1e4c023c7319bf8fa1e.js" defer=""></script>
    <script src="_next/static/chunks/pages/_app-3fa27215a3c41987e6d2.js" defer=""></script>
    <script src="_next/static/chunks/688-b942890a87f9a08b0e31.js" defer=""></script>
    <script src="_next/static/chunks/pages/index-1c2ddd10c81c1e933166.js" defer=""></script>
    <script src="_next/static/vDNOSUkFZmCqphQb-871s/_buildManifest.js" defer=""></script>
    <script src="_next/static/vDNOSUkFZmCqphQb-871s/_ssgManifest.js" defer=""></script>
    <style data-href="https://fonts.googleapis.com/css?family=Lato">
        @font-face {
            font-family: 'Lato';
            font-style: normal;
            font-weight: 400;
            src: url(https://fonts.gstatic.com/s/lato/v23/S6uyw4BMUTPHjx4wWA.woff) format('woff')
        }

        @font-face {
            font-family: 'Lato';
            font-style: normal;
            font-weight: 400;
            src: url(https://fonts.gstatic.com/s/lato/v23/S6uyw4BMUTPHjxAwXiWtFCfQ7A.woff2) format('woff2');
            unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF
        }

        @font-face {
            font-family: 'Lato';
            font-style: normal;
            font-weight: 400;
            src: url(https://fonts.gstatic.com/s/lato/v23/S6uyw4BMUTPHjx4wXiWtFCc.woff2) format('woff2');
            unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD
        }
    </style>
</head>

<body>
    <div id="__next">
        <div class="styles_container__1_WuM">
            <section>
                <div class="personal_profile__BdQI4"><img class="personal_portrait__BAkO0" src="images/1.JPG"
                        alt="pottrait" />
                    <div class="personal_profileInfo__1Y4pW">
                        <h1 class="personal_name__1_mHK">Linzhan Mou</h1>
                        <h3 class="personal_chineseName__18aOD">牟林湛</h3>
                        <h3 class="personal_worksFor__2L0De">Zhejiang University</h3>
                        <div class="personal_links__p_eYL"><span>
                                <a href="mailto:moulz@zju.edu.cn">Email</a></span><span>
                                <a href="https://scholar.google.com/citations?user=cIXq7Z4AAAAJ&hl=en">Google
                                    Scholar</a></span><span>
                                <a href="https://github.com/Friedrich-M">GitHub</a></span><span>
                                <!-- <a href="https://drive.google.com/file/d/1ZZnvbi1r_ptspwEm1XnCW4D_HWcpH354/view?usp=drive_link">CV</a></span><span> -->
                                <a href="https://twitter.com/LinzhanMou">Twitter</a></span>
                            </span>
                        </div>
                    </div>
                </div>
            </section>
            <section>
                <h2>About Me</h2>
                <div>
                    <p>
                        I am a senior undergrad from CKC Honors College at <a
                            href="https://www.zju.edu.cn/english/">Zhejiang University (ZJU)</a> with GPA 3.99/4.0,
                        ranking top 1%.

                        Currently, I am advised by <a href="https://hangzhaomit.github.io/">Prof. Hang Zhao</a> at
                        Tsinghua MARS Lab.

                        I was fortunate to work closely with <a href="https://xzhou.me/">Prof. Xiaowei Zhou</a> at
                        ZJU3DV Lab and <a href="https://yxw.cs.illinois.edu/">Prof. Yu-Xiong Wang</a> at UIUC.

                        I work as a research intern at <a href="https://www.antgroup.com/en">Ant Research</a>, hosted by
                        <a href="https://shenyujun.github.io/">Dr. Yujun Shen</a>.
                    </p>

                    <p>
                        My research interest lies in 3D vision and robotics, specifically focusing on 3D/4D
                        reconstruction, diffusion-guided generation. Recently I'm working on generalizable 3D
                        representation learning for robot navigation and manipulation with diffusion policy.

                    </p>
                </div>
            </section>

            <section>
                <h2> Recent News</h2>
                <ul>
                    <li>
                        Our paper "Instruct 4D-to-4D" accepted by CVPR 2024!
                    </li>
                    <li>
                        Our paper "RelightableAvatar" accepted by CVPR 2024 as Highlight! <img class="emoji"
                            title=":fire:" alt=":fire:"
                            src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png" height="20"
                            width="20">
                    </li>
                </ul>
            </section>

            <section>
                <h2>Publications and Preprints</h2>

                <div class="publication-list_smallText__pUJXB">* denotes equal contribution; ♯ denotes the corresponding
                    author.</div>

                <div class="publication_publication__1Icb_">
                    <div class="publication_image__1EUuC">
                        <video class="vjs-tech" title="Instruct 4D-to-4D video loading.." id="vjs_video_3_html5_api"
                            tabindex="-1" preload="auto" loop="" muted="muted" playsinline="playsinline" autoplay=""
                            src="images/i4d.mp4"></video>
                    </div>

                    <div class="publication_info__kLRGP">
                        <div class="publication_title__3m6SE"> Instruct 4D-to-4D: Editing 4D Scenes as Pseudo-3D Scenes
                            Using 2D Diffusion
                        </div>
                        <div class="publication_authors__qkFXc">
                            <span><u>Linzhan Mou</u></span>
                            <span><a href="https://scholar.google.com/citations?user=_m5__wUAAAAJ&hl=en">Jun-Kun
                                    Chen</a></span>
                            <span><a href="https://yxw.web.illinois.edu/">Yu-Xiong Wang</a><sup>♯</sup></span>
                        </div>
                        <div class="publication_venue__1Dv6R"><span>
                                CVPR 2024</span><span></span></div>
                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a
                                    href="https://drive.google.com/file/d/1drMHkPvZVsbqD5oeJPknuSOrkSlP0aeI/view?usp=drive_link">Paper</a></span>
                            <span class="publication_link__fXY43"><a href="./media/i4d.pptx">Slides</a></span>
                            <span class="publication_link__fXY43"><a>Code</a></span>
                        </div>
                    </div>
                </div>

                <div class="publication_publication__1Icb_">
                    <div class="publication_image__1EUuC">
                        <video class="vjs-tech" title="Relightable and Animatable Neural Avatar video loading.."
                            id="vjs_video_3_html5_api" tabindex="-1" preload="auto" loop="" muted="muted"
                            playsinline="playsinline" autoplay="" src="images/sigasia.mp4"></video>
                    </div>

                    <div class="publication_info__kLRGP">
                        <div class="publication_title__3m6SE"> Relightable and Animatable Neural Avatar from Sparse-View
                            Video
                        </div>
                        <div class="publication_authors__qkFXc">
                            <span><a href="https://zhenx.me/">Zhen Xu</a></span>
                            <span><a href="http://pengsida.net/">Sida Peng</a></span>
                            <span><a href="https://chen-geng.com/">Chen Geng</a></span>
                            <span><u>Linzhan Mou</u></span>
                            <span><a href="https://www.media.mit.edu/people/yzihan/overview/">Zihan Yan</a></span>
                            <span><a href="https://jiamingsun.ml/">Jiaming Sun</a></span>
                            <span><a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a></span>
                            <span><a href="https://xzhou.me/">Xiaowei Zhou</a><sup>♯</sup></span>
                        </div>
                        <div class="publication_venue__1Dv6R"><span>
                                CVPR 2024</span>
                            <span class="publication_highlights__2ILmf">Highlight</span>
                            <span></span>
                        </div>
                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a
                                    href="https://arxiv.org/abs/2308.07903">Paper</a></span>
                            <span class="publication_link__fXY43"><a
                                    href="https://zju3dv.github.io/relightable_avatar/">Project</a></span>
                            <span class="publication_link__fXY43"><a
                                    href="https://github.com/zju3dv/RelightableAvatar">Code</a></span>
                        </div>
                    </div>
                </div>

                <div class="publication_publication__1Icb_">
                    <div class="publication_image__1EUuC"><img src="images/NIPS.png"
                            alt="Reconstructing Hand-Held Objects from Monocular Video thumbnail loading..." />
                    </div>
                    <div class="publication_info__kLRGP">
                        <div class="publication_title__3m6SE">Compact Neural Volumetric Video Representations
                            with Dynamic Codebooks
                        </div>
                        <div class="publication_authors__qkFXc">
                            <!-- <span>  Anonymous authors</span> </div> -->
                            <span><a href="https://github.com/ghy0324">Haoyu Guo</a></span>
                            <span><a href="http://pengsida.net/">Sida Peng</a></span>
                            <span><a href="https://github.com/yunzhiy">Yunzhi Yan</a></span>
                            <span><u>Linzhan Mou</u></span>
                            <span><a href="https://shenyujun.github.io/">Yujun Shen</a></span>
                            <span><a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a></span>
                            <span><a href="https://xzhou.me/">Xiaowei Zhou</a><sup>♯</sup></span>
                        </div>

                        <div class="publication_venue__1Dv6R"><span>NeurIPS 2023 </span><span></span> </div>
                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a
                                    href="https://openreview.net/pdf?id=xTgM7XLN9P">Paper</a></span>
                            <span class="publication_link__fXY43"><a>Project</a></span>
                            <span class="publication_link__fXY43"><a
                                    href="https://github.com/zju3dv/compact_vv">Code</a></span>
                        </div>
                    </div>
                </div>

                <div>
                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC">
                            <video class="vjs-tech" title="Painting 3D Nature in 2D video loading.."
                                id="vjs_video_3_html5_api" tabindex="-1" preload="auto" loop="" muted="muted"
                                playsinline="playsinline" autoplay="" src="images/teaser.mp4"></video>
                        </div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE">Painting 3D Nature in 2D: View Synthesis of Natural
                                Scenes from a Single Semantic Mask</div>
                            <div class="publication_authors__qkFXc">
                                <span><a href="https://zhanghe3z.github.io/">Shangzhan Zhang</a></span>
                                <span><a href="http://pengsida.net/">Sida Peng</a></span>
                                <span><a href="https://tianrun-chen.github.io/">Tianrun Chen</a></span>
                                <span><u>Linzhan Mou</u></span>
                                <span><a href="https://haotongl.github.io/">Haotong Lin</a></span>
                                <span><a href="https://scholar.google.com/citations?user=Jtmq_m0AAAAJ">Kaicheng
                                        Yu</a></span>
                                <span><a href="https://yiyiliao.github.io/">Yiyi Liao</a></span>
                                <span><a href="https://xzhou.me/">Xiaowei Zhou</a><sup>♯</sup></span>
                            </div>
                            <div class="publication_venue__1Dv6R"><span>CVPR 2023 </span>  </div>
                            <div class="publication_links__aEpO_">
                                <span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2302.07224.pdf">Paper</a></span>
                                <span class="publication_link__fXY43"><a
                                        href="https://zju3dv.github.io/paintingnature//">Project</a></span>
                                <span class="publication_link__fXY43"><a
                                        href="https://github.com/zhanghe3z/PaintingNature//">Code</a></span>

                            </div>
                        </div>
                    </div>


                    <div class="publication_publication__1Icb_">
                        <div class="publication_image__1EUuC"><img src="images/attface.png">
                        </div>
                        <div class="publication_info__kLRGP">
                            <div class="publication_title__3m6SE"> MAttFace: High-Resolution Face Swapping with
                                Multi-Level Attention
                            </div>
                            <div class="publication_authors__qkFXc">
                                <span><u>Linzhan Mou*</u></span>
                                <span><a href="https://deepai.org/profile/shaoting-zhu">Shaoting Zhu*</a></span>
                                <span><a href="https://github.com/J1shen">Junyi Shen</a></span>
                                <span><a href="https://april.zju.edu.cn/team/chao-xu/">Chao Xu</a></span>
                                <span><a href="https://april.zju.edu.cn/team/dr-yong-liu/">Yong
                                        Liu</a><sup>♯</sup></span>
                            </div>
                            <div class="publication_venue__1Dv6R"><span> Preprint 2023</div>
                            <div class="publication_links__aEpO_">
                                <span class="publication_link__fXY43"><a>Paper</a></span>
                                <span class="publication_link__fXY43"><a>Project</a></span>
                                <span class="publication_link__fXY43"><a>Code</a></span>
                            </div>
                        </div>
                    </div>


                </div>
            </section>

            <section>
                <h2>Selected Awards and Honors</h2>
                <ul>
                    <li>
                        <div style="display:inline"><i>2020 - 2021</i><!-- -->, </div><span
                            class="styles_collaborator__VflHz"><b>National Scholarship, Ministry of Education of P.R.
                                China (Top 0.2%)</b> </span>
                    </li>
                    <li>
                        <div style="display:inline"><i>2020 - 2023</i><!-- -->, </div><span
                            class="styles_collaborator__VflHz"><b>First-Class Scholarship for Academic Excellence of
                                Zhejiang University (Top 3%) </b> </span>
                    </li>
                    <li>
                        <div style="display:inline"><i>2021 - 2023</i><!-- -->, </div><span
                            class="styles_collaborator__VflHz">Government Scholarship for Academic Excellence of
                            Zhejiang Province (Top 3%) </b></span>
                    </li>
                    <li>
                        <div style="display:inline"><i>2021 - 2022</i><!-- -->, </div><span
                            class="styles_collaborator__VflHz">The Supcon
                            Scholarship, Supcon Technology Group (Top 5%)</b></span>
                    </li>
                    <li>
                        <div style="display:inline"><i>2022</i><!-- -->, </div><span class="styles_collaborator__VflHz">
                            National First Prize, China Undergraduate Mathematical Contest in Modeling
                    </li>
                    <li>
                        <div style="display:inline"><i>2022</i><!-- -->, </div><span class="styles_collaborator__VflHz">
                            International Gold Prize, International Genetically Engineered Machine Competition
                    </li>
                    <li>
                        <div style="display:inline"><i>2022</i><!-- -->, </div><span class="styles_collaborator__VflHz">
                            First Prize, Supcon Cup College Student Robot Competition (Top 1 out of 37 teams)
                    </li>
                </ul>


        </div>
    </div>

    <!-- Default Statcounter code for Personal website https://linzhanm.github.io/
    -->
    <script type="text/javascript">
        var sc_project = 12925377;
        var sc_invisible = 1;
        var sc_security = "43deea45"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics Made Easy -
        Statcounter" href="https://statcounter.com/" target="_blank"><img class="statcounter"
                    src="https://c.statcounter.com/12925377/0/43deea45/1/" alt="Web Analytics Made Easy - Statcounter"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->

</body>

</html>