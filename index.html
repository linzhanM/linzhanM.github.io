<!DOCTYPE html>
<html lang="en">

<head>
    <base target="_blank" />
    <link rel="icon" type="image/x-icon" href="images/favicon.ico" />
    <link rel="preconnect" href="https://fonts.gstatic.com" />
    <link rel="stylesheet" type="text/css" data-href="https://fonts.googleapis.com/css?family=Lato" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <meta name="viewport" content="width=device-width" />
    <meta charSet="utf-8" />
    <!-- <title>Linzhan&#x27;s Homepage</title> -->
    <title>Linzhan Mou</title>
    <meta name="description" content="senior undergraduate student at Zhejiang University.

" />
    <meta name="next-head-count" content="4" />
    <link rel="preload" href="_next/static/css/fd4c9bf86266e80fae27.css" as="style" />
    <link rel="stylesheet" href="_next/static/css/fd4c9bf86266e80fae27.css" data-n-g="" />
    <link rel="preload" href="_next/static/css/06137d006fb8a4f27819.css" as="style" />
    <link rel="stylesheet" href="_next/static/css/06137d006fb8a4f27819.css" data-n-p="" /><noscript
        data-n-css=""></noscript>
    <script defer="" nomodule="" src="_next/static/chunks/polyfills-a54b4f32bdc1ef890ddd.js"></script>
    <script src="_next/static/chunks/webpack-715970c8028b8d8e1f64.js" defer=""></script>
    <script src="_next/static/chunks/framework-64eb7138163e04c228e4.js" defer=""></script>
    <script src="_next/static/chunks/main-a1e4c023c7319bf8fa1e.js" defer=""></script>
    <script src="_next/static/chunks/pages/_app-3fa27215a3c41987e6d2.js" defer=""></script>
    <script src="_next/static/chunks/688-b942890a87f9a08b0e31.js" defer=""></script>
    <script src="_next/static/chunks/pages/index-1c2ddd10c81c1e933166.js" defer=""></script>
    <script src="_next/static/vDNOSUkFZmCqphQb-871s/_buildManifest.js" defer=""></script>
    <script src="_next/static/vDNOSUkFZmCqphQb-871s/_ssgManifest.js" defer=""></script>
    <style data-href="https://fonts.googleapis.com/css?family=Lato">
        @font-face {
            font-family: 'Lato';
            font-style: normal;
            font-weight: 400;
            src: url(https://fonts.gstatic.com/s/lato/v23/S6uyw4BMUTPHjx4wWA.woff) format('woff')
        }

        @font-face {
            font-family: 'Lato';
            font-style: normal;
            font-weight: 400;
            src: url(https://fonts.gstatic.com/s/lato/v23/S6uyw4BMUTPHjxAwXiWtFCfQ7A.woff2) format('woff2');
            unicode-range: U+0100-024F, U+0259, U+1E00-1EFF, U+2020, U+20A0-20AB, U+20AD-20CF, U+2113, U+2C60-2C7F, U+A720-A7FF
        }

        @font-face {
            font-family: 'Lato';
            font-style: normal;
            font-weight: 400;
            src: url(https://fonts.gstatic.com/s/lato/v23/S6uyw4BMUTPHjx4wXiWtFCc.woff2) format('woff2');
            unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD
        }
    </style>
</head>

<body>
    <div id="__next">
        <div class="styles_container__1_WuM">
            <section>
                <div class="personal_profile__BdQI4"><img class="personal_portrait__BAkO0" src="images/1.png"
                        alt="pottrait" />
                    <div class="personal_profileInfo__1Y4pW">
                        <h1 class="personal_name__1_mHK">Linzhan Mou</h1>
                        <h3 class="personal_chineseName__18aOD">牟林湛</h3>
                        <h3 class="personal_worksFor__2L0De">Zhejiang University</h3>
                        <div class="personal_links__p_eYL"><span>
                                <a href="mailto:moulz@zju.edu.cn">Email</a></span><span>
                                <a href="https://scholar.google.com/citations?user=cIXq7Z4AAAAJ">Google
                                    Scholar</a></span><span>
                                <a href="https://github.com/Friedrich-M">GitHub</a></span><span>
                                <a href="https://twitter.com/LinzhanMou">Twitter</a></span>
                            </span>
                        </div>
                    </div>
                </div>
            </section>
            <section>
                <h2>About Me</h2>
                <div>
                    <p>
                        I am a senior undergrad in CSE & CKC Honors College at <a href="https://www.zju.edu.cn/english/">Zhejiang University</a> with GPA of 3.99/4.0.

                        Currently, I am a research assistant advised by <a href="https://www.cis.upenn.edu/~kostas/">Prof. Kostas Daniilidis</a> and <a href="https://lingjie0206.github.io/">Prof. Lingjie Liu</a> at UPenn GRASP Lab and <a href="https://hangzhaomit.github.io/">Prof. Hang Zhao</a> at Tsinghua MARS Lab.

                        Previously, I was privileged to work with <a href="https://yxw.cs.illinois.edu/">Prof. Yu-Xiong Wang</a>, <a href="https://ywang-zju.github.io/">Prof. Yue Wang</a>, and <a href="https://xzhou.me/">Prof. Xiaowei Zhou</a>.
                    </p>

                    <p>
                        My research interests lie at the intersection of computer vision, generative modeling, and robotics, specifically focusing on building intelligent systems that can perceive, understand, and interact with this complex 4D world from everyday photographs and video.


                        <!-- 4D physical understanding for interacting with the world. -->
                        
                        <!-- closing the reality gap in Real2Sim2Real transfer for robotics. -->
                        
                        <!-- My ultimate goal is to develop a physics-aware multi-modal system to better perceive, understand and interact with the 4D open world. -->
                    </p>
                </div>
            </section>

            <!-- <section>
                <h2> Recent News</h2>
                
                <ul>
                    <li>
                        Our paper "DuQuant" accepted by NeurIPS 2024 as Oral! <img class="emoji" title=":fire:" alt=":fire:"
                            src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png" height="20"
                            width="20">
                    </li>
                    <li>
                        Our paper "Let Occ Flow" accepted by CoRL 2024 with all positive score!
                    </li>
                    <li>
                        Our paper "Instruct 4D-to-4D" accepted by CVPR 2024 with all positive score!
                    </li>
                    <li>
                        Our paper "RelightableAvatar" accepted by CVPR 2024 as Highlight! <img class="emoji"
                            title=":fire:" alt=":fire:"
                            src="https://github.githubassets.com/images/icons/emoji/unicode/1f525.png" height="20"
                            width="20">
                    </li>
                </ul>
            </section> -->

                <h2>
                    Publications
                    <br class="publication-list_mobileBreak__24vsO">
                    <span class="publication-list_filters__3ikvu">
                        <span class="publication-list_filter__1x1Xu">
                            <a href="https://linzhanm.github.io/" id="select0" onclick="showPubs(0); return false;" style="text-decoration: underline; color: rgb(0, 0, 99);">show selected</a>
                        </span>
                        <span class="publication-list_filter__1x1Xu">
                            <a href="https://linzhanm.github.io/" id="select1" onclick="showPubs(1); return false;" style="">show all by date</a>
                        </span>
                    </span>
                </h2> 
                
                <script>
                    document.getElementById("select0").addEventListener("click", function() {
                        document.getElementById("select0").style.textDecoration = "underline";
                        document.getElementById("select0").style.color = "rgb(0, 0, 139)";
                        document.getElementById("select1").style.textDecoration = "";
                        document.getElementById("select1").style.color = "";
                    });
                    document.getElementById("select1").addEventListener("click", function() {
                        document.getElementById("select1").style.textDecoration = "underline";
                        document.getElementById("select1").style.color = "rgb(0, 0, 139)";
                        document.getElementById("select0").style.textDecoration = "";
                        document.getElementById("select0").style.color = "";
                    });
                </script>

                <script>
                    function showPubs(index) {
                        var pubs = document.getElementsByClassName("publication_publication__1Icb_");
                        if (index == 0) {
                            for (var i = 0; i < pubs.length; i++) {
                                if (pubs[i].getAttribute("name") == "dimo" || pubs[i].getAttribute("name") == "letoccflow" || pubs[i].getAttribute("name") == "i4d" || pubs[i].getAttribute("name") == "avatar" || pubs[i].getAttribute("name") == "mobile" || pubs[i].getAttribute("name") == "walker" || pubs[i].getAttribute("name") == "saro" || pubs[i].getAttribute("name") == "vr-robo") {
                                    pubs[i].style.display = ""
                                } else {
                                    pubs[i].style.display = "none";
                                }
                            }
                        } else {
                            for (var i = 0; i < pubs.length; i++) {
                                pubs[i].style.display = ""
                            }
                        }
                    }
                </script>

                <div 
                    class="publication-list_smallText__pUJXB">* denotes equal contribution; ♯ denotes the corresponding author. 
                </div>
                <div class="publication_publication__1Icb_" name="dimo">
                    <div class="publication_image__1EUuC" name="dimo">
                        <video class="vjs-tech" title="DIMO video loading.." id="vjs_video_3_html5_api"
                            tabindex="-1" preload="auto" loop="" muted="muted" playsinline="playsinline" autoplay=""
                            src="images/demo.mp4"></video>
                    </div>
                    <div class="publication_info__kLRGP" name="i4d">
                        <div class="publication_title__3m6SE">DIMO: Diverse 3D Motion Generation for Arbitrary Objects</div>
                        <div class="publication_authors__qkFXc">
                            <span><u>Linzhan Mou</u></span>
                            <span><a href="https://www.cis.upenn.edu/~leijh/">Jiahui Lei</a><sup>♯</sup></span>
                            <span><a href="https://cwchenwang.github.io/">Chen Wang</a></span>
                            <span><a href="https://lingjie0206.github.io/">Lingjie Liu</a></span>
                            <span><a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a></span>
                        </div>
                        <div class="publication_venue__1Dv6R"><span>
                            Under Review 2025</span><span></span></div>

                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a href="https://drive.google.com/file/d/11YTgropS_COVTUhq55ZYYwOB155vFaY3/view?usp=drive_link">Paper</a></span>
                            <span class="publication_link__fXY43"><a
                                >Code</a> (coming soon) </span>
                            <span class="publication_link__fXY43"><a href="https://www.youtube.com/watch?v=mwryklD0Cds">Video</a></span>
                            <span class="publication_link__fXY43"><a href="https://youtu.be/mwryklD0Cds">YouTube</a></span>
                        </div>
                    </div>
                </div>

                <div class="publication_publication__1Icb_" name="vr-robo">
                    <div class="publication_image__1EUuC" name="vr-robo">
                        <video class="vjs-tech" title="VR-Robo video loading.." id="vjs_video_3_html5_api"
                            tabindex="-1" preload="auto" loop="" muted="muted" playsinline="playsinline" autoplay=""
                            src="images/rss.mp4"></video>
                    </div>
                    <div class="publication_info__kLRGP" name="vr-robo">
                        <div class="publication_title__3m6SE">VR-Robo: A Real-to-Sim-to-Real System for Robot Navigation and Visual Locomotion
                        </div>
                        <div class="publication_authors__qkFXc">
                            <span><a href="https://zst1406217.github.io/">Shaoting Zhu</a>*</span>
                            <span><u>Linzhan Mou*</u></span>
                            <span><a href="https://scholar.google.com/citations?user=7N0VoNsAAAAJ&hl=en">Runhan Huang</a></span>
                            <span><a href="https://hangzhaomit.github.io/">Hang Zhao</a><sup>♯</sup></span>
                        </div>

                        <div class="publication_venue__1Dv6R"><span>Under Review 2025</span>
                            <!-- <span class="publication_highlights__2ILmf">All Accept</span> -->
                        </div>

                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a
                                >Paper</a></span>
                            <span class="publication_link__fXY43"><a
                                >Code</a> (coming soon) </span>
                            <span class="publication_link__fXY43"><a
                                >Video</a></span>
                            <span class="publication_link__fXY43"><a
                                >YouTube</a></span>
                        </div>
                    </div>
                </div>

                <div class="publication_publication__1Icb_" name="letoccflow">
                    <div class="publication_image__1EUuC" name="letoccflow">
                        <video class="vjs-tech" title="Let Occ Flow video loading.." id="vjs_video_3_html5_api"
                            tabindex="-1" preload="auto" loop="" muted="muted" playsinline="playsinline" autoplay=""
                            src="images/corl.mp4"></video>
                    </div>
                    <div class="publication_info__kLRGP" name="letoccflow">
                        <div class="publication_title__3m6SE">Let Occ Flow: Self-Supervised 3D Occupancy Flow Prediction
                        </div>
                        <div class="publication_authors__qkFXc">
                            <span><u>Linzhan Mou*</u></span>
                            <span><a href="https://scholar.google.com/citations?user=pBEZ7V4AAAAJ&hl=zh-CN">Yili Liu</a>*</span>
                            <span><a href="https://scholar.google.com/citations?hl=zh-CN&user=4Ry3CKsAAAAJ">Xuan Yu</a></span>
                            <span><a >Chenrui Han</a></span>
                            <span><a >Sitong Mao</a></span>
                            <a href="https://scholar.google.com/citations?user=1hI9bqUAAAAJ&hl=en">Rong Xiong,</a>
                            <span><a href="https://ywang-zju.github.io/">Yue Wang</a><sup>♯</sup></span>
                        </div>

                        <div class="publication_venue__1Dv6R"><span>CoRL 2024</span>
                            <!-- <span class="publication_highlights__2ILmf">All Accept</span> -->
                        </div>

                        

                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a
                                href="https://arxiv.org/abs/2407.07587">arXiv</a></span>
                            <span class="publication_link__fXY43"><a
                                href="https://eliliu2233.github.io/letoccflow/">Project</a></span>
                            <span class="publication_link__fXY43"><a
                                href="https://github.com/eliliu2233/occ-flow">Code</a></span>
                            <span class="publication_link__fXY43"><a
                                href="https://eliliu2233.github.io/letoccflow/static/videos/letoccflow.mp4">Video</a></span>
                            <span class="publication_link__fXY43"><a
                                href="./images/letoccflow-poster.pdf">Poster</a></span>
                        </div>
                    </div>
                </div>

                <div class="publication_publication__1Icb_" name="i4d">
                    <div class="publication_image__1EUuC" name="i4d">
                        <video class="vjs-tech" title="Instruct 4D-to-4D video loading.." id="vjs_video_3_html5_api"
                            tabindex="-1" preload="auto" loop="" muted="muted" playsinline="playsinline" autoplay=""
                            src="images/cvpr.mp4"></video>
                    </div>

                    <div class="publication_info__kLRGP" name="i4d">
                        <div class="publication_title__3m6SE">Instruct 4D-to-4D: Editing 4D Scenes as Pseudo-3D Scenes Using 2D Diffusion</div>
                        <div class="publication_authors__qkFXc">
                            <span><u>Linzhan Mou</u></span>
                            <span><a href="https://scholar.google.com/citations?user=_m5__wUAAAAJ&hl=en">Jun-Kun Chen</a></span>
                            <span><a href="https://yxw.web.illinois.edu/">Yu-Xiong Wang</a><sup>♯</sup></span>
                        </div>
                        <div class="publication_venue__1Dv6R"><span>
                            CVPR 2024</span><span></span></div>
                        <!-- <div class="publication_venue__1Dv6R"><span>
                            also in Multimodal AI Workshop</span>
                            <span class="publication_highlights__2ILmf">Oral</span>
                            <span></span>
                        </div> -->

                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a
                                href="https://arxiv.org/abs/2406.09402">arXiv</a></span>
                            <span class="publication_link__fXY43"><a
                                href="https://immortalco.github.io/Instruct-4D-to-4D/">Project</a></span>
                            <span class="publication_link__fXY43"><a href="https://github.com/Friedrich-M/Instruct-4D-to-4D">Code</a></span>
                            <span class="publication_link__fXY43"><a>Video</a></span>
                            <span class="publication_link__fXY43"><a href="./images/i4d-poster.pdf">Poster</a></span>
                        </div>
                    </div>
                </div>

                <div class="publication_publication__1Icb_" name="avatar">
                    <div class="publication_image__1EUuC" name="avatar">
                        <video class="vjs-tech" title="Relightable and Animatable Neural Avatar video loading.."
                            id="vjs_video_3_html5_api" tabindex="-1" preload="auto" loop="" muted="muted"
                            playsinline="playsinline" autoplay="" src="images/sigasia.mp4"></video>
                    </div>

                    <div class="publication_info__kLRGP" name="avatar">
                        <div class="publication_title__3m6SE"> Relightable and Animatable Neural Avatar from Sparse-View Video
                        </div>
                        <div class="publication_authors__qkFXc">
                            <span><a href="https://zhenx.me/">Zhen Xu</a></span>
                            <span><a href="http://pengsida.net/">Sida Peng</a></span>
                            <span><a href="https://chen-geng.com/">Chen Geng</a></span>
                            <span><u>Linzhan Mou</u></span>
                            <span><a href="https://www.media.mit.edu/people/yzihan/overview/">Zihan Yan</a></span>
                            <span><a href="https://jiamingsun.ml/">Jiaming Sun</a></span>
                            <span><a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a></span>
                            <span><a href="https://xzhou.me/">Xiaowei Zhou</a><sup>♯</sup></span>
                        </div>
                        <div class="publication_venue__1Dv6R"><span>
                                CVPR 2024</span>
                            <span class="publication_highlights__2ILmf">Highlight</span>
                            <span></span>
                        </div>
                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a
                                    href="https://arxiv.org/abs/2308.07903">arXiv</a></span>
                            <span class="publication_link__fXY43"><a
                                    href="https://zju3dv.github.io/relightable_avatar/">Project</a></span>
                            <span class="publication_link__fXY43"><a
                                    href="https://github.com/zju3dv/RelightableAvatar">Code</a></span>
                            <span class="publication_link__fXY43"><a
                                href="https://www.youtube.com/watch?v=bZaP0PXUWdc">Video</a></span>
                            <span class="publication_link__fXY43"><a
                                href="./images/avatar-poster.pdf">Poster</a></span>
                        </div>
                    </div>
                </div>

                <!-- <div class="publication_publication__1Icb_" name="duquant" style="display: none;">
                    <div class="publication_image__1EUuC" name="duquant">
                        <img src="images/llm.png"
                            alt="Reconstructing Hand-Held Objects from Monocular Video thumbnail loading..." />
                    </div>

                    <div class="publication_info__kLRGP" name="duquant">
                        <div class="publication_title__3m6SE"> DuQuant: Distributing Outliers via Dual
                            Transformation Makes Stronger Quantized LLMs
                        </div>
                        <div class="publication_authors__qkFXc">
                            <span>Anonymous authors</span>
                        </div>
                        <div class="publication_venue__1Dv6R"><span>
                                NeurIPS 2024</span>
                            <span class="publication_highlights__2ILmf">Oral</span>
                            <span></span>
                        </div>
                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a
                                    href="https://arxiv.org/abs/2406.01721">arXiv</a></span>
                            <span class="publication_link__fXY43"><a
                                    >Code</a></span>
                            <span class="publication_link__fXY43"><a
                                >Poster</a></span>
                        </div>
                    </div>
                </div> -->

                <div class="publication_publication__1Icb_" name="compactvv" style="display: none;">
                    <div class="publication_image__1EUuC" name="compactvv">
                        <img src="images/NIPS.png"
                            alt="Reconstructing Hand-Held Objects from Monocular Video thumbnail loading..." />
                    </div>
                    <div class="publication_info__kLRGP" name="compactvv">
                        <div class="publication_title__3m6SE">Compact Neural Volumetric Video Representations
                            with Dynamic Codebooks
                        </div>
                        <div class="publication_authors__qkFXc">
                            <span><a href="https://github.com/ghy0324">Haoyu Guo</a></span>
                            <span><a href="http://pengsida.net/">Sida Peng</a></span>
                            <span><a href="https://yunzhiy.github.io/">Yunzhi Yan</a></span>
                            <span><u>Linzhan Mou</u></span>
                            <span><a href="https://shenyujun.github.io/">Yujun Shen</a></span>
                            <span><a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a></span>
                            <span><a href="https://xzhou.me/">Xiaowei Zhou</a><sup>♯</sup></span>
                        </div>

                        <div class="publication_venue__1Dv6R"><span>NeurIPS 2023 </span><span></span> </div>
                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a
                                    href="https://openreview.net/pdf?id=xTgM7XLN9P">Paper</a></span>
                            <span class="publication_link__fXY43"><a
                                    href="https://github.com/zju3dv/compact_vv">Code</a></span>
                            <span class="publication_link__fXY43"><a
                                    href="https://neurips.cc/media/PosterPDFs/NeurIPS%202023/70004.png?t=1702193339.444763">Poster</a></span>
                        </div>
                    </div>
                </div>

                <div>
                    <div class="publication_publication__1Icb_" name="paintingnature" style="display: none;">
                        <div class="publication_image__1EUuC" name="paintingnature">
                            <video class="vjs-tech" title="Painting 3D Nature in 2D video loading.."
                                id="vjs_video_3_html5_api" tabindex="-1" preload="auto" loop="" muted="muted"
                                playsinline="playsinline" autoplay="" src="images/teaser.mp4"></video>
                        </div>
                        <div class="publication_info__kLRGP" name="paintingnature">
                            <div class="publication_title__3m6SE">Painting 3D Nature in 2D: View Synthesis of Natural
                                Scenes from a Single Semantic Mask</div>
                            <div class="publication_authors__qkFXc">
                                <span><a href="https://zhanghe3z.github.io/">Shangzhan Zhang</a></span>
                                <span><a href="http://pengsida.net/">Sida Peng</a></span>
                                <span><a href="https://tianrun-chen.github.io/">Tianrun Chen</a></span>
                                <span><u>Linzhan Mou</u></span>
                                <span><a href="https://haotongl.github.io/">Haotong Lin</a></span>
                                <span><a href="https://scholar.google.com/citations?user=Jtmq_m0AAAAJ">Kaicheng Yu</a></span>
                                <span><a href="https://yiyiliao.github.io/">Yiyi Liao</a></span>
                                <span><a href="https://xzhou.me/">Xiaowei Zhou</a><sup>♯</sup></span>
                            </div>
                            <div class="publication_venue__1Dv6R"><span>CVPR 2023 </span> </div>
                            <div class="publication_links__aEpO_">
                                <span class="publication_link__fXY43"><a
                                        href="https://arxiv.org/abs/2302.07224.pdf">arXiv</a></span>
                                <span class="publication_link__fXY43"><a
                                        href="https://zju3dv.github.io/paintingnature//">Project</a></span>
                                <span class="publication_link__fXY43"><a
                                        href="https://github.com/zhanghe3z/PaintingNature//">Code</a></span>
                            </div>
                        </div>
                    </div>


                    <div class="publication_publication__1Icb_" name="attface" style="display: none;">
                        <div class="publication_image__1EUuC" name="attface">
                            <img src="images/attface.png">
                        </div>
                        <div class="publication_info__kLRGP" name="attface">
                            <div class="publication_title__3m6SE"> MAttFace: High-Resolution Face Swapping with
                                Multi-Level Attention
                            </div>
                            <div class="publication_authors__qkFXc">
                                <span><u>Linzhan Mou*</u></span>
                                <span><a href="https://zst1406217.github.io/">Shaoting Zhu*</a></span>
                                <span><a href="">Junyi Shen</a></span>
                                <span><a href="https://april.zju.edu.cn/team/chao-xu/">Chao Xu</a></span>
                                <span><a href="https://april.zju.edu.cn/team/dr-yong-liu/">Yong
                                        Liu</a><sup>♯</sup></span>
                            </div>
                            <div class="publication_venue__1Dv6R"><span> Preprint 2023</div>
                            <div class="publication_venue__1Dv6R"><span> My first computer vision project</div>
                            <div class="publication_links__aEpO_">
                                <span class="publication_link__fXY43"><a>Paper</a></span>
                                <span class="publication_link__fXY43"><a>Project</a></span>
                                <span class="publication_link__fXY43"><a>Code</a></span>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section>
                <h2>
                    Robotics Projects
                    <br class="publication-list_mobileBreak__24vsO">
                </h2> 

                <div class="publication_publication__1Icb_" name="walker">
                    <div class="publication_image__1EUuC" name="walker">
                        <video class="vjs-tech" title="Robust Robot Walker video loading.."
                            id="vjs_video_3_html5_api" tabindex="-1" preload="auto" loop="" muted="muted"
                            playsinline="playsinline" autoplay="" src="images/icra.mp4"></video>
                    </div>
                    <div class="publication_info__kLRGP" name="avatar">
                        <div class="publication_title__3m6SE"> Robust Robot Walker: Learning Agile Locomotion over Tiny Traps
                        </div>
                        <div class="publication_authors__qkFXc">
                            <span>
                                To enables quadruped robots to pass various small obstacles, we incorporate a contact encoder and a classification head to learn implicit representations of traps and design tailored reward functions to improve stability.
                            </span>
                        </div>
                        
                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a
                                    href="https://robust-robot-walker.github.io/">Project</a></span>
                            <span class="publication_link__fXY43"><a
                                href="https://youtu.be/eVvEu1nQFvk">YouTube</a></span>
                            <span class="publication_link__fXY43"><a
                                href="https://www.bilibili.com/video/BV1R64qesE4u/">Bilibili</a></span>
                        </div>
                    </div>
                </div>

                <div class="publication_publication__1Icb_" name="saro">
                    <div class="publication_image__1EUuC" name="saro">
                        <video class="vjs-tech" title="SARO video loading.."
                            id="vjs_video_3_html5_api" tabindex="-1" preload="auto" loop="" muted="muted"
                            playsinline="playsinline" autoplay="" src="images/saro.mp4"></video>
                    </div>
                    <div class="publication_info__kLRGP" name="avatar">
                        <div class="publication_title__3m6SE"> SARO: Space-Aware Robot System for Terrain Crossing via VLM
                        </div>
                        <div class="publication_authors__qkFXc">
                            <span>
                                To enble robot navigate across 3D terrains, we leverage VLM for high-level reasoning and execution, with a design of task decomposition and closedloop sub-task execution.
                            </span>
                        </div>
                        <div class="publication_links__aEpO_">
                            <span class="publication_link__fXY43"><a
                                    href="https://saro-vlm.github.io/">Project</a></span>
                            <span class="publication_link__fXY43"><a
                                href="https://youtu.be/nzzRdFPNHMs">YouTube</a></span>
                            <span class="publication_link__fXY43"><a
                                href="https://www.bilibili.com/video/BV1uMtreoE6n/">Bilibili</a></span>
                        </div>
                    </div>
                </div>

                <div class="publication_publication__1Icb_" name="mobile">
                    <div class="publication_image__1EUuC" name="mobile">
                        <video class="vjs-tech" title="Mobile Manipulator video loading.."
                            id="vjs_video_3_html5_api" tabindex="-1" preload="auto" loop="" muted="muted"
                            playsinline="playsinline" autoplay="" src="images/robot.mp4"></video>
                    </div>
                    <div class="publication_info__kLRGP" name="mobile">
                        <div class="publication_title__3m6SE"> Vision-Centric Mobile Manipulator
                        </div>
                        <div class="publication_authors__qkFXc">
                            <span>
                                To enable agents to autonomously navigate and grasp objects in complex factory environments, we design a mobile manipulator, with YOLO-based detection module, patrol navigation module, and grasp planning module.
                            </span>
                        </div>
                        <div class="publication_venue__1Dv6R"><span>
                                First Prize in "Supcon Cup" Robot Competition</span> 
                            <span></span>
                        </div>
                        
                    </div>
                </div>

            <section>
                <h2>Experiences</h2>
                <table cellspacing="17">
                    <tbody>
                        <tr>
                            <td width="15%">
                                <img style="width: 100%; max-height: 100px; max-width: 100px; object-fit: cover;" src="./images/uiuc.png">
                            </td>
                            <td>
                                <div class="institution">Visiting Student, CS, UIUC</div>
                                <div class="period">Jul. 2023 - Jan. 2024</div>
                                <div class="region">Urbana, IL, USA</div>
                            </td>
                            <td width="15%">
                                <img style="width: 100%; max-height: 95px; max-width: 95px; object-fit: cover;" src="./images/ant.png">
                            </td>
                            <td>
                                <div class="institution">Research Intern, Ant Research</div>
                                <div class="period">Feb. 2024 - Jun. 2024</div>
                                <div class="region">Hangzhou, China</div>
                            </td>      
                        </tr>
                        <tr>    
                            <td width="15%">
                                <img style="width: 100%; max-height: 100px; max-width: 100px; object-fit: cover;" src="./images/tsinghua.png">
                            </td>
                            <td>
                                <div class="institution">Research Intern, IIIS, THU</div>
                                <div class="period">Jun. 2024 - Present</div>
                                <!-- <div class="advisor">Advisor: <a href="https://hangzhaomit.github.io">Prof. Hang Zhao</a></div> -->
                                <div class="region">Beijing, China</div>
                            </td>
                            <td width="15%">
                                <img style="width: 100%; max-height: 95px; max-width: 95px; object-fit: cover;" src="./images/penn2.png">
                            </td>
                            <td>
                                <div class="institution">Research Assistant, CIS, UPenn</div>
                                <div class="period">Jul. 2024 - Present</div>
                                <!-- <div class="advisor">Advisor: <a href="https://www.cis.upenn.edu/~kostas/">Prof. Kostas Daniilidis</a></div> -->
                                <div class="region">Philadelphia, PA, USA</div>
                            </td>
                        </tr>
                    </tbody>
                </table>

                <section>
                    <h2>Employment</h2>
                    <table cellspacing="17">
                        <tbody>
                            <tr>
                                <td width="15%">
                                    <img style="width: 100%; max-height: 100px; max-width: 100px; object-fit: cover;" src="./images/manifold.png">
                                </td>
                                <td>
                                    <div class="institution">Tech Co-founder, Manifold AI</div>
                                    <div class="work"> Product Delivered: <a href="https://www.manifold-s.com/">Klein</a></div> 
                                    <div class="region">
                                        Engine for controllable 3D scene GenAI,
                                        diverse training scenes for embodied AI,
                                        intergrating any real-world objects with 360° identicality
                                    </div>
                                </td>
                            </tr> 
                        </tbody>
                    </table>

            <section>
                <h2>Selected Honors and Awards</h2>
                <ul>
                    <li>
                        <span class="styles_collaborator__VflHz">China National Scholarship </span>
                    </li>
                    <li>
                        <span class="styles_collaborator__VflHz">First-Class Scholarship of
                                Zhejiang University </span>
                    </li>
                    <li>
                        <span class="styles_collaborator__VflHz">Government Scholarship of
                            Zhejiang Province </b></span>
                    </li>
                    <li>
                        <span class="styles_collaborator__VflHz">Top 10 Outstanding Students of Qiushi Institute </b></span>
                    </li>
                    <li>
                        <span class="styles_collaborator__VflHz">
                            National First Prize in China Mathematical Contest in Modeling 
                    </li>
                </ul>

            <footer class="styles_footer__3qp3V"><p>Last updated on <time datetime="Sat Jan 20 2025">Jan. 20, 2025</time></p><p>© 2020-<!-- -->2025<!-- --> Linzhan Mou. All rights reserved.</p></footer>

        </div>
    </div>

    <!-- Default Statcounter code for Personal website https://linzhanm.github.io/
    -->
    <script type="text/javascript">
        var sc_project = 12925377;
        var sc_invisible = 1;
        var sc_security = "43deea45"; 
    </script>
    <script type="text/javascript" src="https://www.statcounter.com/counter/counter.js" async></script>
    <noscript>
        <div class="statcounter"><a title="Web Analytics Made Easy -
        Statcounter" href="https://statcounter.com/" target="_blank"><img class="statcounter"
                    src="https://c.statcounter.com/12925377/0/43deea45/1/" alt="Web Analytics Made Easy - Statcounter"
                    referrerPolicy="no-referrer-when-downgrade"></a></div>
    </noscript>
    <!-- End of Statcounter Code -->

</body>

</html>